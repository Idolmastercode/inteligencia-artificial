# ğŸ“Š PrÃ¡ctica de IA: AnÃ¡lisis de Rendimiento de Modelos PequeÃ±os

## IntroducciÃ³n

El objetivo de esta prÃ¡ctica fue evaluar la capacidad de 5 modelos de IA pequeÃ±os (phi3:mini, gemma:2b, tinydolphin, tinyllama, qwen:0.5b) para comprender y responder a preguntas especÃ­ficas basadas en un temario de nivel universitario (Asignatura: Inteligencia Artificial, Clave: SCC-1012).

La evaluaciÃ³n se centrÃ³ en la **precisiÃ³n**, el **seguimiento de instrucciones** y la **coherencia** de las respuestas.

---

## Tabla Comparativa de Rendimiento

Se utilizÃ³ un sistema de semÃ¡foros para una evaluaciÃ³n visual rÃ¡pida del desempeÃ±o en cada pregunta.

| Modelo | Q1 (Objetivo) | Q2 (Algoritmo A*) | Q3 (Razonamiento) | Q4 (SBR) | Q5 (Aplicaciones) | Veredicto |
| :--- | :---: | :---: | :---: | :---: | :---: | :--- |
| **phi3:mini** | ğŸŸ¢ | ğŸŸ¢ | ğŸŸ¢ | ğŸŸ¡ | ğŸŸ¢ | **Ã‰xito Sobresaliente** |
| **gemma:2b** | ğŸŸ¡ | ğŸŸ¡ | ğŸ”´ | ğŸ”´ | ğŸŸ¢ | **Rendimiento Mixto** |
| **tinyllama** | ğŸŸ¡ | ğŸ”´ | ğŸ”´ | ğŸ”´ | ğŸ”´ | **Fallo CrÃ­tico (AlucinaciÃ³n)** |
| **tinydolphin** | ğŸ”´ | ğŸ”´ | ğŸ”´ | ğŸ”´ | ğŸ”´ | **Fallo CrÃ­tico (Formato)** |
| **qwen:0.5b** | ğŸ”´ | ğŸ”´ | ğŸ”´ | ğŸ”´ | ğŸ”´ | **Fallo CrÃ­tico (No-Respuesta)** |

**Leyenda:**
* ğŸŸ¢ **Verde:** Respuesta precisa y contextualizada al temario.
* ğŸŸ¡ **Amarillo:** Respuesta parcialmente correcta, genÃ©rica o vaga.
* ğŸ”´ **Rojo:** Respuesta incorrecta, alucinada, o no se proporcionÃ³ respuesta a la pregunta.

---

## AnÃ¡lisis Detallado por Modelo

### ğŸ¥‡ Ganador Indiscutible: phi3:mini

Este modelo demostrÃ³ una capacidad superior para asimilar el contexto del temario y responder con precisiÃ³n.

* **Q1 (Objetivo):** CapturÃ³ perfectamente la esencia del temario ("capacitar al ingeniero", "modelos matemÃ¡ticos", "problemas complejos").
* **Q2 (A\*):** Dio la mejor definiciÃ³n, mencionando "bÃºsqueda", "navegaciÃ³n por camino", "heurÃ­stica" y "minimizaciÃ³n del costo".
* **Q3 (Razonamiento):** DefiniÃ³ correctamente la diferencia clave: el razonamiento no-monÃ³tono permite que las conclusiones cambien con nueva informaciÃ³n.
* **Q4 (SBR):** IdentificÃ³ los componentes clave ("base de conocimiento" y "reglas"), aunque omitiÃ³ el "mecanismo de control" explÃ­cito.
* **Q5 (Aplicaciones):** ListÃ³ las 6 aplicaciones correctamente y aÃ±adiÃ³ descripciones (aunque con algunos errores tipogrÃ¡ficos).

**ConclusiÃ³n:** `phi3:mini` fue el Ãºnico modelo que no solo *recuperÃ³* informaciÃ³n, sino que pareciÃ³ *entender* los conceptos de IA sobre los que se le preguntaba.

---

### ğŸ¥ˆ Rendimiento Mixto: gemma:2b

Este modelo logrÃ³ completar algunas tareas simples de recuperaciÃ³n, pero fallÃ³ en las explicaciones conceptuales.

* **Q1 (Objetivo):** Dio una respuesta genÃ©rica. Correcta, pero no tan adaptada al temario como `phi3`.
* **Q2 (A\*):** Respuesta demasiado simple ("encontrar los caminos mÃ¡s cortos"). Es correcta, pero le falta la profundidad de una respuesta de nivel universitario.
* **Q3 y Q4 (Razonamiento y SBR):** Sus respuestas fueron vagas y conceptualmente incorrectas. ("mÃºltiples lÃ³gicas" no es la definiciÃ³n de razonamiento no-monÃ³tono).
* **Q5 (Aplicaciones):** **Ã‰xito total**. ListÃ³ las 6 aplicaciones de forma limpia y precisa.

**ConclusiÃ³n:** `gemma:2b` es eficaz para tareas de extracciÃ³n o listado de datos simples, pero no se le debe confiar la explicaciÃ³n de conceptos complejos.

---

### âŒ Fallo CrÃ­tico (AlucinaciÃ³n): tinyllama

Este modelo no solo fallÃ³ en responder correctamente, sino que **inventÃ³ activamente informaciÃ³n** (alucinÃ³) que no estaba en el temario.

* **Q2 (A\*):** Fallo garrafal. DescribiÃ³ A\* como un algoritmo para "ajuste de ventanillas" y lo confundiÃ³ con el conocimiento no-monÃ³tono.
* **Q3 (Razonamiento):** OmitiÃ³ la pregunta por completo.
* **Q4 (SBR):** AlucinaciÃ³n severa. InventÃ³ un concepto de "siete sÃ­mbolos" y lo relacionÃ³ con "HTML" y "pÃ¡ginas web".
* **Q5 (Aplicaciones):** ListÃ³ 6 elementos, pero *ninguno* correspondÃ­a a la lista del Tema 4. InventÃ³ su propia lista.

**ConclusiÃ³n:** `tinyllama` es un ejemplo claro de los peligros de la alucinaciÃ³n en modelos pequeÃ±os. No es fiable para tareas basadas en contexto.

---

### âŒ Fallo CrÃ­tico (Formato y Coherencia): tinydolphin y qwen:0.5b

Estos dos modelos fallaron en el nivel mÃ¡s bÃ¡sico de la tarea: no pudieron seguir la instrucciÃ³n de "responder las 5 preguntas".

* **tinydolphin:** No respondiÃ³ las preguntas. En su lugar, generÃ³ un resumen del temario, pero lo hizo de forma incorrecta, mezclando los contenidos de los temas (ej. puso "reglas y bÃºsqueda" en el Tema 2, cuando estÃ¡ en el Tema 3).
* **qwen:0.5b:** No generÃ³ ninguna respuesta. Simplemente repitiÃ³ las preguntas y, en el proceso, asignÃ³ incorrectamente los nÃºmeros de los temas (ej. dijo que A\* estaba en el Tema 2).

**ConclusiÃ³n:** Estos modelos no fueron capaces de procesar la instrucciÃ³n (Preguntas + Contexto) y fallaron la prueba por completo.

---

## ğŸ’¡ Conclusiones Generales de la PrÃ¡ctica

1.  **La Brecha de Capacidad es Enorme:** No todos los modelos "pequeÃ±os" son iguales. `phi3:mini` demostrÃ³ capacidades de razonamiento contextual que lo colocan en una categorÃ­a muy superior a los demÃ¡s.
2.  **Riesgo de AlucinaciÃ³n vs. Vaguedad:** Es mÃ¡s fÃ¡cil detectar un modelo "malo" (como `tinyllama`) que alucina respuestas absurdas, que un modelo "mediocre" (como `gemma:2b`) que da respuestas vagas pero plausibles.
3.  **La ComprensiÃ³n del Contexto es Clave:** La mayorÃ­a de los modelos (excepto `phi3`) ignoraron el temario. `tinyllama` y `tinydolphin` lo usaron incorrectamente, y `gemma` pareciÃ³ ignorarlo en favor de respuestas genÃ©ricas. `phi3` fue el Ãºnico que lo usÃ³ como la "fuente de verdad".
4.  **El Seguimiento de Instrucciones no estÃ¡ Garantizado:** Dos de los cinco modelos (`tinydolphin` y `qwen`) fallaron la tarea mÃ¡s simple: el formato de Pregunta y Respuesta.