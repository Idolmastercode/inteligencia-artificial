{
    "cells": [
        {
            "cell_type": "markdown",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Importaciones y Configuraci\u00f3n de GPU\n",
                "Configuraci\u00f3n de memoria para evitar errores en WSL/Linux con tarjetas NVIDIA.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import os\n",
                "import re\n",
                "import gc\n",
                "import cv2\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import classification_report\n",
                "import tensorflow as tf\n",
                "import keras\n",
                "from keras.utils import to_categorical\n",
                "from keras.models import Sequential, Model, load_model\n",
                "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU, Input\n",
                "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
                "\n",
                "%matplotlib inline\n",
                "\n",
                "# Limpieza preventiva\n",
                "tf.keras.backend.clear_session()\n",
                "gc.collect()\n",
                "\n",
                "# Configuraci\u00f3n GPU\n",
                "gpus = tf.config.list_physical_devices('GPU')\n",
                "if gpus:\n",
                "    try:\n",
                "        for gpu in gpus:\n",
                "            tf.config.experimental.set_memory_growth(gpu, True)\n",
                "        print(f\"\u2705 GPU Detectada y Configurada: {gpus[0].name}\")\n",
                "    except RuntimeError as e:\n",
                "        print(e)\n",
                "else:\n",
                "    print(\"\u26a0\ufe0f No se detect\u00f3 GPU. Se usar\u00e1 CPU.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Carga y Procesamiento de Im\u00e1genes\n",
                "Leemos las im\u00e1genes de la carpeta `./dataset_animals`, las redimensionamos a 100x100 y las convertimos a Arrays.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "imgpath = \"./dataset_animals\" \n",
                "IMG_SIZE = 100\n",
                "EPOCHS = 40\n",
                "BATCH_SIZE = 64\n",
                "\n",
                "images = []\n",
                "directories = []\n",
                "dircount = []\n",
                "prevRoot = ''\n",
                "cant = 0\n",
                "\n",
                "print(f\"\ud83d\udcc2 Leyendo im\u00e1genes de: {imgpath}\")\n",
                "\n",
                "if not os.path.exists(imgpath):\n",
                "    print(f\"\u274c ERROR: La ruta {imgpath} no existe.\")\n",
                "else:\n",
                "    for root, dirnames, filenames in os.walk(imgpath):\n",
                "        for filename in filenames:\n",
                "            if re.search(r\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename, re.IGNORECASE):\n",
                "                try:\n",
                "                    filepath = os.path.join(root, filename)\n",
                "                    # Lectura con OpenCV y resize\n",
                "                    image = cv2.imread(filepath)\n",
                "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
                "                    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
                "                    images.append(image)\n",
                "                    cant += 1\n",
                "                    \n",
                "                    if prevRoot != root:\n",
                "                        print(f\"   Directorio: {root} | Cantidad: {cant}\")\n",
                "                        prevRoot = root\n",
                "                        directories.append(root)\n",
                "                        dircount.append(cant)\n",
                "                        cant = 0\n",
                "                except Exception as e:\n",
                "                    print(f\"Error: {e}\")\n",
                "\n",
                "    if cant > 0:\n",
                "        dircount.append(cant)\n",
                "    # Ajuste de listas\n",
                "    if len(dircount) > len(directories):\n",
                "        dircount = dircount[1:]\n",
                "    \n",
                "    print(f'Total im\u00e1genes: {sum(dircount)}')\n",
                "\n",
                "# Creaci\u00f3n de etiquetas\n",
                "labels = []\n",
                "indice = 0\n",
                "animal_names = []\n",
                "for cantidad in dircount:\n",
                "    for i in range(cantidad):\n",
                "        labels.append(indice)\n",
                "    indice += 1\n",
                "\n",
                "# Nombres de clases\n",
                "for directorio in directories:\n",
                "    name = os.path.basename(directorio)\n",
                "    animal_names.append(name)\n",
                "\n",
                "y = np.array(labels)\n",
                "X = np.array(images, dtype=np.uint8)\n",
                "\n",
                "print(\"Clases detectadas:\", animal_names)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Preparaci\u00f3n de Datasets (Train/Test/Val)\n",
                "Normalizaci\u00f3n (0-1) y One-Hot Encoding.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split inicial\n",
                "train_X, test_X, train_Y, test_Y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# Normalizaci\u00f3n\n",
                "train_X = train_X.astype('float32') / 255.0\n",
                "test_X = test_X.astype('float32') / 255.0\n",
                "\n",
                "# One-hot encoding\n",
                "train_Y_one_hot = to_categorical(train_Y)\n",
                "test_Y_one_hot = to_categorical(test_Y)\n",
                "\n",
                "# Split validaci\u00f3n\n",
                "train_X, valid_X, train_label, valid_label = train_test_split(\n",
                "    train_X, train_Y_one_hot, test_size=0.2, random_state=13\n",
                ")\n",
                "\n",
                "print(f\"Formas: Train:{train_X.shape}, Val:{valid_X.shape}, Test:{test_X.shape}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Definici\u00f3n del Modelo CNN\n",
                "Modelo secuencial adaptado para entrada de 100x100x3.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "INIT_LR = 1e-3\n",
                "nClasses = len(animal_names)\n",
                "\n",
                "animal_model = Sequential()\n",
                "animal_model.add(Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
                "\n",
                "# Bloque 1\n",
                "animal_model.add(Conv2D(32, kernel_size=(3, 3), activation='linear', padding='same'))\n",
                "animal_model.add(LeakyReLU(alpha=0.1))\n",
                "animal_model.add(BatchNormalization())\n",
                "animal_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
                "animal_model.add(Dropout(0.25))\n",
                "\n",
                "# Bloque 2\n",
                "animal_model.add(Conv2D(64, kernel_size=(3, 3), activation='linear', padding='same'))\n",
                "animal_model.add(LeakyReLU(alpha=0.1))\n",
                "animal_model.add(BatchNormalization())\n",
                "animal_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
                "animal_model.add(Dropout(0.25))\n",
                "\n",
                "# Bloque 3\n",
                "animal_model.add(Conv2D(128, kernel_size=(3, 3), activation='linear', padding='same'))\n",
                "animal_model.add(LeakyReLU(alpha=0.1))\n",
                "animal_model.add(BatchNormalization())\n",
                "animal_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
                "animal_model.add(Dropout(0.4))\n",
                "\n",
                "# Salida\n",
                "animal_model.add(Flatten())\n",
                "animal_model.add(Dense(128, activation='linear'))\n",
                "animal_model.add(LeakyReLU(alpha=0.1))\n",
                "animal_model.add(Dropout(0.5))\n",
                "animal_model.add(Dense(nClasses, activation='softmax'))\n",
                "\n",
                "animal_model.compile(\n",
                "    loss=keras.losses.categorical_crossentropy,\n",
                "    optimizer=keras.optimizers.Adagrad(learning_rate=INIT_LR),\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "animal_model.summary()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Entrenamiento\n",
                "Usamos EarlyStopping y Checkpoints para guardar el mejor modelo.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
                "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
                "checkpoint = ModelCheckpoint('animales_best.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
                "\n",
                "print(\"\ud83d\ude80 Entrenando...\")\n",
                "animal_train = animal_model.fit(\n",
                "    train_X, train_label, \n",
                "    batch_size=BATCH_SIZE,\n",
                "    epochs=EPOCHS,\n",
                "    verbose=1,\n",
                "    validation_data=(valid_X, valid_label), \n",
                "    callbacks=[early_stop, reduce_lr, checkpoint]\n",
                ")\n",
                "\n",
                "animal_model.save(\"animales_final_100x100.keras\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Evaluaci\u00f3n de M\u00e9tricas y Gr\u00e1ficos\n",
                "Visualizamos la p\u00e9rdida y precisi\u00f3n durante el entrenamiento.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_eval = animal_model.evaluate(test_X, test_Y_one_hot, verbose=1)\n",
                "print(f'Test loss: {test_eval[0]}')\n",
                "print(f'Test accuracy: {test_eval[1]}')\n",
                "\n",
                "accuracy = animal_train.history['accuracy']\n",
                "val_accuracy = animal_train.history['val_accuracy']\n",
                "loss = animal_train.history['loss']\n",
                "val_loss = animal_train.history['val_loss']\n",
                "epochs_range = range(len(accuracy))\n",
                "\n",
                "plt.figure(figsize=(12, 5))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(epochs_range, accuracy, 'bo', label='Training accuracy')\n",
                "plt.plot(epochs_range, val_accuracy, 'b', label='Validation accuracy')\n",
                "plt.title('Accuracy')\n",
                "plt.legend()\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(epochs_range, loss, 'bo', label='Training loss')\n",
                "plt.plot(epochs_range, val_loss, 'b', label='Validation loss')\n",
                "plt.title('Loss')\n",
                "plt.legend()\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7. Visualizaci\u00f3n de Resultados\n",
                "Mostramos ejemplos de predicciones correctas e incorrectas del set de prueba.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predicted_classes_raw = animal_model.predict(test_X)\n",
                "predicted_classes = np.argmax(predicted_classes_raw, axis=1)\n",
                "\n",
                "# \u00cdndices de correctos e incorrectos\n",
                "correct = np.where(predicted_classes == test_Y)[0]\n",
                "incorrect = np.where(predicted_classes != test_Y)[0]\n",
                "\n",
                "print(f\"\u2705 Correctas: {len(correct)} | \u274c Incorrectas: {len(incorrect)}\")\n",
                "\n",
                "# Gr\u00e1fica de Correctos\n",
                "plt.figure(figsize=(10,10))\n",
                "for i, correct_idx in enumerate(correct[:9]):\n",
                "    plt.subplot(3,3,i+1)\n",
                "    plt.imshow(test_X[correct_idx])\n",
                "    plt.title(f\"Pred: {animal_names[predicted_classes[correct_idx]]} \\n Real: {animal_names[test_Y[correct_idx]]}\", color='green')\n",
                "    plt.axis('off')\n",
                "plt.suptitle(\"Predicciones Correctas\")\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Gr\u00e1fica de Incorrectos\n",
                "if len(incorrect) > 0:\n",
                "    plt.figure(figsize=(10,10))\n",
                "    for i, incorrect_idx in enumerate(incorrect[:9]):\n",
                "        plt.subplot(3,3,i+1)\n",
                "        plt.imshow(test_X[incorrect_idx])\n",
                "        plt.title(f\"Pred: {animal_names[predicted_classes[incorrect_idx]]} \\n Real: {animal_names[test_Y[incorrect_idx]]}\", color='red')\n",
                "        plt.axis('off')\n",
                "    plt.suptitle(\"Predicciones Incorrectas\")\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Classification Report\n",
                "target_names_list = [f\"{name}\" for name in animal_names]\n",
                "print(classification_report(test_Y, predicted_classes, target_names=target_names_list))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 8. Prueba con Im\u00e1genes Externas (Carpeta `tests`)\n",
                "Prueba del modelo con im\u00e1genes nuevas que no ha visto antes.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "folder_tests = './tests'\n",
                "test_images_ext = []\n",
                "test_filenames = []\n",
                "\n",
                "if not os.path.exists(folder_tests):\n",
                "    print(f\"\u26a0\ufe0f La carpeta {folder_tests} no existe.\")\n",
                "else:\n",
                "    valid_exts = ('.jpg', '.jpeg', '.png', '.bmp')\n",
                "    for archivo in os.listdir(folder_tests):\n",
                "        if archivo.lower().endswith(valid_exts):\n",
                "            path = os.path.join(folder_tests, archivo)\n",
                "            try:\n",
                "                img = cv2.imread(path)\n",
                "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
                "                test_images_ext.append(img)\n",
                "                test_filenames.append(archivo)\n",
                "            except:\n",
                "                pass\n",
                "\n",
                "    if test_images_ext:\n",
                "        X_ext = np.array(test_images_ext, dtype=np.uint8).astype('float32') / 255.0\n",
                "        preds_ext = animal_model.predict(X_ext)\n",
                "        \n",
                "        plt.figure(figsize=(15, 5))\n",
                "        for i, pred in enumerate(preds_ext[:5]): # Mostrar 5\n",
                "            idx = np.argmax(pred)\n",
                "            conf = pred[idx] * 100\n",
                "            plt.subplot(1, 5, i+1)\n",
                "            plt.imshow(test_images_ext[i])\n",
                "            plt.title(f\"{animal_names[idx]}\\n{conf:.1f}%\")\n",
                "            plt.axis('off')\n",
                "        plt.show()\n",
                "    else:\n",
                "        print(\"No hay im\u00e1genes en /tests\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}