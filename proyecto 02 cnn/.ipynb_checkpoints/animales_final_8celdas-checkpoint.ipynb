{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32990439",
   "metadata": {},
   "source": [
    "# 1. Importaciones y Configuraci√≥n GPU\n",
    "Librer√≠as necesarias y configuraci√≥n de memoria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e52cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Limpieza y Configuraci√≥n GPU\n",
    "tf.keras.backend.clear_session()\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"‚úÖ GPU Detectada: {gpus[0].name}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Usando CPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a925141",
   "metadata": {},
   "source": [
    "# 2. Carga del Dataset\n",
    "Usamos 'image_dataset_from_directory' para crear los generadores de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33409b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgpath = \"./dataset\"\n",
    "IMG_SIZE = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "print(f\"Leyendo im√°genes de {imgpath}...\")\n",
    "\n",
    "# Dataset de Entrenamiento (80%)\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    imgpath, validation_split=0.2, subset=\"training\", seed=123,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, label_mode='categorical'\n",
    ")\n",
    "\n",
    "# Dataset de Validaci√≥n (20%)\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    imgpath, validation_split=0.2, subset=\"validation\", seed=123,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, label_mode='categorical'\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "nClasses = len(class_names)\n",
    "print(f\"\\nClases encontradas ({nClasses}): {class_names}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feeb7f2",
   "metadata": {},
   "source": [
    "# 3. Visualizaci√≥n de los Datos\n",
    "Mostramos ejemplos de lo que acaba de cargar la red para verificar que todo est√© bien.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32ffd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        # Argmax para convertir one-hot a indice\n",
    "        idx = np.argmax(labels[i])\n",
    "        plt.title(class_names[idx])\n",
    "        plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027e4ad2",
   "metadata": {},
   "source": [
    "# 4. Optimizaci√≥n y Normalizaci√≥n\n",
    "Aplicamos cach√© y prefetch para que la GPU nunca se detenga esperando datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a020a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Normalizaci√≥n de 0-255 a 0-1\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# Cache y Prefetch\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"‚úÖ Datos optimizados y listos para entrar a la red.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4064e5e0",
   "metadata": {},
   "source": [
    "# 5. Definici√≥n del Modelo CNN\n",
    "Estructura de la red neuronal convolucional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a98787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "\n",
    "# Bloque 1\n",
    "model.add(layers.Conv2D(32, (3, 3), padding='same', activation='linear'))\n",
    "model.add(layers.LeakyReLU(alpha=0.1))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "# Bloque 2\n",
    "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='linear'))\n",
    "model.add(layers.LeakyReLU(alpha=0.1))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "# Bloque 3\n",
    "model.add(layers.Conv2D(128, (3, 3), padding='same', activation='linear'))\n",
    "model.add(layers.LeakyReLU(alpha=0.1))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "# Clasificaci√≥n\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='linear'))\n",
    "model.add(layers.LeakyReLU(alpha=0.1))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(nClasses, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cec26a2",
   "metadata": {},
   "source": [
    "# 6. Entrenamiento\n",
    "Iniciamos el proceso de aprendizaje.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241e79ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1),\n",
    "    ModelCheckpoint('mi_modelo_animales.keras', save_best_only=True, monitor='val_loss')\n",
    "]\n",
    "\n",
    "print(\"üöÄ Entrenando...\")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27319df6",
   "metadata": {},
   "source": [
    "# 7. Resultados Gr√°ficos\n",
    "Curvas de precisi√≥n (Accuracy) y p√©rdida (Loss).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d352ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b72be7",
   "metadata": {},
   "source": [
    "# 8. Validaci√≥n Visual y Test Externo\n",
    "Matriz de predicciones correctas vs incorrectas y prueba con carpeta 'tests'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19809d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Obtener predicciones del set de validaci√≥n\n",
    "print(\"Generando predicciones de validaci√≥n...\")\n",
    "val_images = []\n",
    "val_labels = []\n",
    "val_preds = []\n",
    "\n",
    "# Tomamos un lote para visualizar\n",
    "for images, labels in val_ds.take(1):\n",
    "    preds = model.predict(images)\n",
    "    val_images = images.numpy()\n",
    "    val_labels = np.argmax(labels.numpy(), axis=1)\n",
    "    val_preds = np.argmax(preds, axis=1)\n",
    "\n",
    "# √çndices\n",
    "correct = np.where(val_preds == val_labels)[0]\n",
    "incorrect = np.where(val_preds != val_labels)[0]\n",
    "\n",
    "print(f\"En este lote: Correctas: {len(correct)} | Incorrectas: {len(incorrect)}\")\n",
    "\n",
    "# Gr√°fica Correctas\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.suptitle(\"Predicciones CORRECTAS\")\n",
    "for i, idx in enumerate(correct[:5]):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(val_images[idx])\n",
    "    plt.title(f\"{class_names[val_preds[idx]]}\", color='green')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Gr√°fica Incorrectas\n",
    "if len(incorrect) > 0:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.suptitle(\"Predicciones INCORRECTAS\")\n",
    "    for i, idx in enumerate(incorrect[:5]):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        plt.imshow(val_images[idx])\n",
    "        plt.title(f\"P:{class_names[val_preds[idx]]}\\nR:{class_names[val_labels[idx]]}\", color='red')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# TEST EXTERNO\n",
    "print(\"\\n--- TEST CARPETA EXTERNA ---\")\n",
    "folder = './tests'\n",
    "if os.path.exists(folder):\n",
    "    for f in os.listdir(folder):\n",
    "        if f.endswith(('.jpg', '.png')):\n",
    "            img = cv2.imread(os.path.join(folder, f))\n",
    "            if img is not None:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img_r = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                img_batch = np.expand_dims(img_r, axis=0).astype('float32')/255.0\n",
    "                pred = model.predict(img_batch, verbose=0)\n",
    "                idx = np.argmax(pred)\n",
    "                print(f\"üì∏ {f} -> üêæ {class_names[idx]} ({pred[0][idx]*100:.2f}%)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
