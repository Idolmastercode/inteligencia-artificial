{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777e1a2d",
   "metadata": {},
   "source": [
    "# 1. Importaciones y Configuraci√≥n de GPU\n",
    "Configuraci√≥n de memoria para evitar errores en WSL/Linux con tarjetas NVIDIA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bee489bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765995415.605961  159505 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "I0000 00:00:1765995416.273595  159505 cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765995418.023442  159505 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GPU Detectada y Configurada: /physical_device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1765995418.869099  159505 cuda_executor.cc:1839] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W0000 00:00:1765995419.290413  159505 cuda_executor.cc:1839] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W0000 00:00:1765995419.290917  159505 cuda_executor.cc:1839] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W0000 00:00:1765995419.290935  159505 gpu_device.cc:2456] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU, Input\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Limpieza preventiva\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "# Configuraci√≥n GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"‚úÖ GPU Detectada y Configurada: {gpus[0].name}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se detect√≥ GPU. Se usar√° CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a33cb1b",
   "metadata": {},
   "source": [
    "# 2. Carga y Procesamiento de Im√°genes\n",
    "Leemos las im√°genes de la carpeta `./dataset_animals`, las redimensionamos a 100x100 y las convertimos a Arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73ef1357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Leyendo im√°genes de: ./dataset\n",
      "   Directorio: ./dataset/tortugas | Cantidad: 1\n",
      "   Directorio: ./dataset/perros | Cantidad: 10860\n",
      "   Directorio: ./dataset/gato | Cantidad: 10768\n",
      "   Directorio: ./dataset/hormigas | Cantidad: 10528\n",
      "   Directorio: ./dataset/mariquitas | Cantidad: 10008\n",
      "Total im√°genes: 52723\n",
      "Clases detectadas: ['tortugas', 'perros', 'gato', 'hormigas', 'mariquitas']\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# REEMPLAZA LA CELDA 2 CON ESTO\n",
    "# ==========================================\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Configuraci√≥n\n",
    "imgpath = \"./dataset\" \n",
    "IMG_SIZE = 100\n",
    "class_names = [] # Para guardar los nombres de \"Gato\", \"Perro\", etc.\n",
    "\n",
    "images = []\n",
    "labels = [] # Esta vez llenamos las etiquetas AL MISMO TIEMPO\n",
    "\n",
    "print(f\"üìÇ Buscando carpetas en: {imgpath}\")\n",
    "\n",
    "if not os.path.exists(imgpath):\n",
    "    print(f\"‚ùå ERROR: La ruta {imgpath} no existe.\")\n",
    "else:\n",
    "    # 1. Obtener lista de carpetas (clases) ordenadas\n",
    "    # Esto asegura que el √≠ndice 0 siempre sea la misma clase\n",
    "    carpetas = sorted([d for d in os.listdir(imgpath) if os.path.isdir(os.path.join(imgpath, d))])\n",
    "    class_names = carpetas\n",
    "    \n",
    "    print(f\"Clases detectadas: {class_names}\")\n",
    "\n",
    "    # 2. Recorrer cada carpeta espec√≠fica\n",
    "    for indice, nombre_carpeta in enumerate(carpetas):\n",
    "        ruta_carpeta = os.path.join(imgpath, nombre_carpeta)\n",
    "        print(f\"üîÑ Procesando clase '{nombre_carpeta}' (√çndice {indice})...\")\n",
    "        \n",
    "        archivos = os.listdir(ruta_carpeta)\n",
    "        count_local = 0\n",
    "        \n",
    "        for archivo in archivos:\n",
    "            if archivo.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):\n",
    "                try:\n",
    "                    ruta_img = os.path.join(ruta_carpeta, archivo)\n",
    "                    \n",
    "                    # Leer y procesar\n",
    "                    image = cv2.imread(ruta_img)\n",
    "                    \n",
    "                    if image is None:\n",
    "                        # Si cv2 no pudo leerla (archivo corrupto), la saltamos\n",
    "                        continue\n",
    "                        \n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "                    \n",
    "                    # === AQU√ç EST√Å LA SOLUCI√ìN ===\n",
    "                    # Agregamos imagen y etiqueta JUNTAS. \n",
    "                    # Si falla la imagen, no se agrega ninguna de las dos.\n",
    "                    images.append(image)\n",
    "                    labels.append(indice)\n",
    "                    \n",
    "                    count_local += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error en {archivo}: {e}\")\n",
    "        \n",
    "        print(f\"   ‚úÖ {count_local} im√°genes cargadas de {nombre_carpeta}\")\n",
    "\n",
    "    # Convertir a Numpy Arrays\n",
    "    X = np.array(images, dtype=np.uint8)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    print(\"\\n================RESUMEN=================\")\n",
    "    print(f\"Total Im√°genes (X): {len(X)}\")\n",
    "    print(f\"Total Etiquetas (y): {len(y)}\")\n",
    "    \n",
    "    # Verificaci√≥n final de seguridad\n",
    "    if len(X) == len(y):\n",
    "        print(\"‚úÖ ¬°Sincronizaci√≥n perfecta! Puedes continuar con la siguiente celda.\")\n",
    "    else:\n",
    "        print(\"‚ùå ERROR CR√çTICO: Siguen disparejos (esto no deber√≠a pasar con este c√≥digo).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325a268c",
   "metadata": {},
   "source": [
    "# 3. Preparaci√≥n de Datasets (Train/Test/Val)\n",
    "Normalizaci√≥n (0-1) y One-Hot Encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e105e80",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [52724, 52723]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Split inicial\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_X, test_X, train_Y, test_Y = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Normalizaci√≥n\u001b[39;00m\n\u001b[32m      5\u001b[39m train_X = train_X.astype(\u001b[33m'\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m'\u001b[39m) / \u001b[32m255.0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/proenv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/proenv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2916\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_arrays == \u001b[32m0\u001b[39m:\n\u001b[32m   2914\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAt least one array required as input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2916\u001b[39m arrays = \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2918\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m   2919\u001b[39m n_train, n_test = _validate_shuffle_split(\n\u001b[32m   2920\u001b[39m     n_samples, test_size, train_size, default_test_size=\u001b[32m0.25\u001b[39m\n\u001b[32m   2921\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/proenv/lib/python3.11/site-packages/sklearn/utils/validation.py:530\u001b[39m, in \u001b[36mindexable\u001b[39m\u001b[34m(*iterables)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[32m    501\u001b[39m \n\u001b[32m    502\u001b[39m \u001b[33;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    526\u001b[39m \u001b[33;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[32m    527\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    529\u001b[39m result = [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[32m--> \u001b[39m\u001b[32m530\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/proenv/lib/python3.11/site-packages/sklearn/utils/validation.py:473\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    471\u001b[39m lengths = [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lengths)) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    474\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    476\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [52724, 52723]"
     ]
    }
   ],
   "source": [
    "# Split inicial\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizaci√≥n\n",
    "train_X = train_X.astype('float32') / 255.0\n",
    "test_X = test_X.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encoding\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "# Split validaci√≥n\n",
    "train_X, valid_X, train_label, valid_label = train_test_split(\n",
    "    train_X, train_Y_one_hot, test_size=0.2, random_state=13\n",
    ")\n",
    "\n",
    "print(f\"Formas: Train:{train_X.shape}, Val:{valid_X.shape}, Test:{test_X.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec44e856",
   "metadata": {},
   "source": [
    "# 4. Definici√≥n del Modelo CNN\n",
    "Modelo secuencial adaptado para entrada de 100x100x3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6d69cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-3\n",
    "nClasses = len(animal_names)\n",
    "\n",
    "animal_model = Sequential()\n",
    "animal_model.add(Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "\n",
    "# Bloque 1\n",
    "animal_model.add(Conv2D(32, kernel_size=(3, 3), activation='linear', padding='same'))\n",
    "animal_model.add(LeakyReLU(alpha=0.1))\n",
    "animal_model.add(BatchNormalization())\n",
    "animal_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "animal_model.add(Dropout(0.25))\n",
    "\n",
    "# Bloque 2\n",
    "animal_model.add(Conv2D(64, kernel_size=(3, 3), activation='linear', padding='same'))\n",
    "animal_model.add(LeakyReLU(alpha=0.1))\n",
    "animal_model.add(BatchNormalization())\n",
    "animal_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "animal_model.add(Dropout(0.25))\n",
    "\n",
    "# Bloque 3\n",
    "animal_model.add(Conv2D(128, kernel_size=(3, 3), activation='linear', padding='same'))\n",
    "animal_model.add(LeakyReLU(alpha=0.1))\n",
    "animal_model.add(BatchNormalization())\n",
    "animal_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "animal_model.add(Dropout(0.4))\n",
    "\n",
    "# Salida\n",
    "animal_model.add(Flatten())\n",
    "animal_model.add(Dense(128, activation='linear'))\n",
    "animal_model.add(LeakyReLU(alpha=0.1))\n",
    "animal_model.add(Dropout(0.5))\n",
    "animal_model.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "animal_model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer=keras.optimizers.Adagrad(learning_rate=INIT_LR),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "animal_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42a182f",
   "metadata": {},
   "source": [
    "# 5. Entrenamiento\n",
    "Usamos EarlyStopping y Checkpoints para guardar el mejor modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631feebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "checkpoint = ModelCheckpoint('animales_best.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "print(\"üöÄ Entrenando...\")\n",
    "animal_train = animal_model.fit(\n",
    "    train_X, train_label, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    validation_data=(valid_X, valid_label), \n",
    "    callbacks=[early_stop, reduce_lr, checkpoint]\n",
    ")\n",
    "\n",
    "animal_model.save(\"animales_final_100x100.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05cacd",
   "metadata": {},
   "source": [
    "# 6. Evaluaci√≥n de M√©tricas y Gr√°ficos\n",
    "Visualizamos la p√©rdida y precisi√≥n durante el entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0589428",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = animal_model.evaluate(test_X, test_Y_one_hot, verbose=1)\n",
    "print(f'Test loss: {test_eval[0]}')\n",
    "print(f'Test accuracy: {test_eval[1]}')\n",
    "\n",
    "accuracy = animal_train.history['accuracy']\n",
    "val_accuracy = animal_train.history['val_accuracy']\n",
    "loss = animal_train.history['loss']\n",
    "val_loss = animal_train.history['val_loss']\n",
    "epochs_range = range(len(accuracy))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs_range, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs_range, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8f5aee",
   "metadata": {},
   "source": [
    "# 7. Visualizaci√≥n de Resultados\n",
    "Mostramos ejemplos de predicciones correctas e incorrectas del set de prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66a1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes_raw = animal_model.predict(test_X)\n",
    "predicted_classes = np.argmax(predicted_classes_raw, axis=1)\n",
    "\n",
    "# √çndices de correctos e incorrectos\n",
    "correct = np.where(predicted_classes == test_Y)[0]\n",
    "incorrect = np.where(predicted_classes != test_Y)[0]\n",
    "\n",
    "print(f\"‚úÖ Correctas: {len(correct)} | ‚ùå Incorrectas: {len(incorrect)}\")\n",
    "\n",
    "# Gr√°fica de Correctos\n",
    "plt.figure(figsize=(10,10))\n",
    "for i, correct_idx in enumerate(correct[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(test_X[correct_idx])\n",
    "    plt.title(f\"Pred: {animal_names[predicted_classes[correct_idx]]} \\n Real: {animal_names[test_Y[correct_idx]]}\", color='green')\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"Predicciones Correctas\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Gr√°fica de Incorrectos\n",
    "if len(incorrect) > 0:\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i, incorrect_idx in enumerate(incorrect[:9]):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(test_X[incorrect_idx])\n",
    "        plt.title(f\"Pred: {animal_names[predicted_classes[incorrect_idx]]} \\n Real: {animal_names[test_Y[incorrect_idx]]}\", color='red')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(\"Predicciones Incorrectas\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Classification Report\n",
    "target_names_list = [f\"{name}\" for name in animal_names]\n",
    "print(classification_report(test_Y, predicted_classes, target_names=target_names_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c32118",
   "metadata": {},
   "source": [
    "# 8. Prueba con Im√°genes Externas (Carpeta `tests`)\n",
    "Prueba del modelo con im√°genes nuevas que no ha visto antes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cec662",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_tests = './tests'\n",
    "test_images_ext = []\n",
    "test_filenames = []\n",
    "\n",
    "if not os.path.exists(folder_tests):\n",
    "    print(f\"‚ö†Ô∏è La carpeta {folder_tests} no existe.\")\n",
    "else:\n",
    "    valid_exts = ('.jpg', '.jpeg', '.png', '.bmp')\n",
    "    for archivo in os.listdir(folder_tests):\n",
    "        if archivo.lower().endswith(valid_exts):\n",
    "            path = os.path.join(folder_tests, archivo)\n",
    "            try:\n",
    "                img = cv2.imread(path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                test_images_ext.append(img)\n",
    "                test_filenames.append(archivo)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    if test_images_ext:\n",
    "        X_ext = np.array(test_images_ext, dtype=np.uint8).astype('float32') / 255.0\n",
    "        preds_ext = animal_model.predict(X_ext)\n",
    "        \n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for i, pred in enumerate(preds_ext[:5]): # Mostrar 5\n",
    "            idx = np.argmax(pred)\n",
    "            conf = pred[idx] * 100\n",
    "            plt.subplot(1, 5, i+1)\n",
    "            plt.imshow(test_images_ext[i])\n",
    "            plt.title(f\"{animal_names[idx]}\\n{conf:.1f}%\")\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No hay im√°genes en /tests\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
